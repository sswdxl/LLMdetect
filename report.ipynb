{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To fully utilize the data features, we concatenate the text with its corresponding prompt. Try to extract features from the concatenated data. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading data files\n",
    "essays_df = pd.read_csv('llm-detect-ai-generated-text/train_essays.csv')\n",
    "prompts_df = pd.read_csv('llm-detect-ai-generated-text/train_prompts.csv')\n",
    "\n",
    "# Link text with corresponding prompts\n",
    "merged_df = essays_df.merge(prompts_df, on='prompt_id', how='left')\n",
    "merged_df['text'] = merged_df['prompt_name'] + '\\n\\n' + merged_df['instructions'] + '\\n\\n' + merged_df['text']\n",
    "merged_df.drop(merged_df.columns[[4, 5, 6]],axis=1, inplace=True)\n",
    "\n",
    "merged_df.to_csv('llm-detect-ai-generated-text/train_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities\\n\\nWrite an explanatory essay ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities\\n\\nWrite an explanatory essay ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities\\n\\nWrite an explanatory essay ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  \\\n",
       "0  0059830c          0  Car-free cities\\n\\nWrite an explanatory essay ...   \n",
       "1  005db917          0  Car-free cities\\n\\nWrite an explanatory essay ...   \n",
       "2  008f63e3          0  Car-free cities\\n\\nWrite an explanatory essay ...   \n",
       "\n",
       "   generated  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of essays: 1378\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numbers of essays: {merged_df.id.unique().shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtdata = []\n",
    "classes = []\n",
    "for row in merged_df.itertuples():\n",
    "    txtdata.append(row[3])\n",
    "    classes.append(row[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Data Division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since there is no verifiable test set in the dataset, in order to evaluate the model, we re-divide the training set into a training set and a test set, where 20% of the data is used for the test evaluation. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "\n",
    "# Split the data set using the train_test_split methodï¼Œ 20% for test sets\n",
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(txtdata, classes, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'list'>\n",
      "label type: <class 'list'>\n",
      "train size: 1102\n",
      "test size: 276\n"
     ]
    }
   ],
   "source": [
    "print(\"data type:\", type(train_data))\n",
    "print(\"label type:\", type(train_labels))\n",
    "print(\"train size:\",len(train_data))\n",
    "print(\"test size:\",len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Sentence Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vector Model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0e303747744547bff0da07e490d781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get sentence vector\n",
    "train_feature = model.encode(train_data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the vectorised abstract: (768,)\n",
      "Shape of the embeddings: (1102, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the vectorised abstract: {train_feature[0].shape}')\n",
    "print(f'Shape of the embeddings: {train_feature.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn logistic regression classifier using CV\n",
    "from numpy import *\n",
    "logreg = linear_model.LogisticRegressionCV(Cs=logspace(-4,4,20), cv=5, n_jobs=-1)\n",
    "logreg.fit(train_feature, train_labels)\n",
    "\n",
    "print(\"w=\", logreg.coef_)\n",
    "print(\"b=\", logreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "acc = metrics.accuracy_score(test_labels, predY)\n",
    "print(\"test accuracy=\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Analysis and ComparisonS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
